{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8A2wnTFTa1X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BSWRmz3oSMsB",
        "outputId": "5c0f155a-a63b-48d5-8acc-7e8b7dcf72e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/basilb2s/language-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 542k/542k [00:00<00:00, 44.2MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/basilb2s/language-detection/versions/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"basilb2s/language-detection\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxuvgpd_TEn_",
        "outputId": "cd5d40ae-0373-4ffd-b9c7-2dabea1689e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Text Language\n",
            "0   Nature, in the broadest sense, is the natural...  English\n",
            "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
            "2  The study of nature is a large, if not the onl...  English\n",
            "3  Although humans are part of nature, human acti...  English\n",
            "4  [1] The word nature is borrowed from the Old F...  English \n",
            "\n",
            "Index(['Text', 'Language'], dtype='object') \n",
            "\n",
            "['English' 'Malayalam' 'Hindi' 'Tamil' 'Portugeese' 'French' 'Dutch'\n",
            " 'Spanish' 'Greek' 'Russian' 'Danish' 'Italian' 'Turkish' 'Sweedish'\n",
            " 'Arabic' 'German' 'Kannada'] \n",
            "\n",
            "Number of rows - 10337 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(os.path.join(path, \"Language Detection.csv\"))\n",
        "print(f\"{df.head()} \\n\")\n",
        "print(f\"{df.columns} \\n\")\n",
        "print(f\"{df['Language'].unique()} \\n\")\n",
        "print(f\"Number of rows - {(df.shape[0])} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYB8y7_97Mxl",
        "outputId": "f75be5bd-1c6a-4225-9f1a-0dc78d34b82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    Text Language\n",
            "347                             Kennedy.  English\n",
            "750                                GNE).  English\n",
            "1074                        wasn't able.  English\n",
            "1100                        how are you?  English\n",
            "1102                    how's it going?.  English\n",
            "...                                  ...      ...\n",
            "10275  ನಾನು ನಿಮ್ಮೊಂದಿಗೆ ಸರಿಯಾಗಿರುತ್ತೇನೆ.  Kannada\n",
            "10276                 ಕ್ಷಮೆಯಾಚಿಸುತ್ತಿದೆ.  Kannada\n",
            "10279              ಅದರ ಬಗ್ಗೆ ಚಿಂತಿಸಬೇಡಿ.  Kannada\n",
            "10280                        ಚಿಂತಿಸಬೇಡಿ.  Kannada\n",
            "10320                      ನೀನು ತಿನ್ನು.  Kannada\n",
            "\n",
            "[1156 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df_filtered = df[df[\"Text\"].str.split().str.len() < 4]\n",
        "print(df_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFZMC5M0-gxC"
      },
      "outputs": [],
      "source": [
        "df = df[~((df[\"Text\"].str.split().str.len() == 1) & (df[\"Text\"].str.len() < 3))]\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9g9F0Gs-zcl"
      },
      "outputs": [],
      "source": [
        "ABBREVIATIONS = set([\n",
        "    # **English**\n",
        "    \"p.m.\", \"a.m.\", \"dr.\", \"mr.\", \"mrs.\", \"u.s.a.\", \"e.g.\", \"i.e.\", \"etc.\", \"vs.\", \"fig.\", \"vol.\", \"no.\", \"pp.\", \"gov.\", \"dept.\", \"lt.\", \"gen.\", \"inc.\", \"corp.\", \"est.\", \"prof.\", \"ph.d.\", \"jr.\", \"sr.\", \"st.\", \"mt.\", \"rev.\", \"ft.\", \"sq.\", \"yr.\", \"min.\", \"sec.\",\n",
        "\n",
        "    # **French**\n",
        "    \"m.\", \"mme.\", \"mlle.\", \"dr.\", \"av.\", \"boul.\", \"ch.\", \"fig.\", \"etc.\", \"p.ex.\", \"cf.\", \"ibid.\", \"op.cit.\", \"c.-à-d.\", \"n.b.\", \"p.j.\", \"t.s.v.p.\", \"env.\", \"gov.\", \"dir.\", \"adm.\", \"prof.\", \"ph.d.\",\n",
        "\n",
        "    # **German**\n",
        "    \"p.m.\", \"a.m.\", \"d.h.\", \"z.B.\", \"u.a.\", \"etc.\", \"vgl.\", \"usw.\", \"bzw.\", \"ff.\", \"u.E.\", \"g.U.\", \"g.g.A.\", \"Buchst.\", \"u.s.w.\", \"sog.\", \"u.ä.\", \"Std.\", \"evtl.\", \"Zt.\", \"Chr.\", \"u.U.\", \"o.ä.\", \"Ltd.\", \"b.A.\", \"z.Zt.\", \"spp.\", \"sen.\", \"SA\", \"k.o.\", \"jun.\", \"i.H.v.\", \"dgl.\", \"dergl.\", \"Co.\", \"zzt.\", \"usf.\", \"s.p.a.\", \"Dkr.\", \"Corp.\", \"bzgl.\", \"BSE\",\n",
        "\n",
        "    # **Spanish**\n",
        "    \"p.ej.\", \"etc.\", \"s.a.\", \"sr.\", \"sra.\", \"dr.\", \"prof.\", \"pág.\", \"núm.\", \"gral.\", \"av.\", \"c/\", \"dpto.\", \"c.c.\", \"ud.\", \"u.d.\", \"u.s.\", \"u.v.\", \"a.c.\", \"d.c.\", \"admón.\", \"corp.\",\n",
        "\n",
        "    # **Portuguese**\n",
        "    \"sr.\", \"sra.\", \"dr.\", \"prof.\", \"av.\", \"pág.\", \"etc.\", \"ex.\", \"obs.\", \"exmo.\", \"adm.\", \"corp.\", \"ilmo.\", \"u.s.\", \"u.v.\", \"a.c.\", \"d.c.\", \"n.º\", \"s.l.\", \"fasc.\",\n",
        "\n",
        "    # **Dutch**\n",
        "    \"blz.\", \"bijv.\", \"ca.\", \"dhr.\", \"dr.\", \"e.d.\", \"e.v.\", \"enz.\", \"fig.\", \"gem.\", \"i.h.b.\", \"m.a.w.\", \"m.n.\", \"m.v.g.\", \"n.a.v.\", \"nr.\", \"o.a.\", \"o.i.\", \"p.m.\", \"pag.\", \"t.o.v.\", \"t.z.t.\", \"vlg.\", \"zgn.\", \"z.i.\", \"z.s.m.\", \"z.v.h.\",\n",
        "\n",
        "    # **Italian**\n",
        "    \"sig.\", \"sig.ra\", \"sig.na\", \"ecc.\", \"dr.\", \"prof.\", \"s.p.a.\", \"s.r.l.\", \"es.\", \"avv.\", \"ing.\", \"dott.\", \"p.zza\", \"v.le\", \"c.so\", \"b.s.\", \"c.m.\", \"s.n.c.\", \"n.b.\", \"c.c.\",\n",
        "\n",
        "    # **Swedish**\n",
        "    \"bl.a.\", \"d.v.s.\", \"m.fl.\", \"m.m.\", \"nr.\", \"o.s.v.\", \"s.a.s.\", \"t.ex.\", \"m.a.o.\", \"jfr.\", \"ibid.\", \"c:a\", \"p.g.a.\", \"m.h.t.\", \"d.g.s.\", \"d.o.\",\n",
        "\n",
        "    # **Danish**\n",
        "    \"bl.a.\", \"ca.\", \"dvs.\", \"m.fl.\", \"m.m.\", \"nr.\", \"osv.\", \"t.ex.\", \"m.a.o.\", \"jfr.\", \"ibid.\", \"c:a\", \"p.g.a.\", \"f.eks.\", \"mht.\", \"a.s.\", \"cvr.\",\n",
        "\n",
        "    # **Greek**\n",
        "    \"κλπ.\", \"π.χ.\", \"δηλ.\", \"κ.α.\", \"ο.ε.\", \"σ.σ.\", \"βλ.\", \"περ.\", \"σελ.\", \"κα.\", \"γ.τ.λ.\", \"γ.τ.κ.\",\n",
        "\n",
        "    # **Russian**\n",
        "    \"и т.д.\", \"и др.\", \"и пр.\", \"г.\", \"ул.\", \"д.\", \"кв.\", \"км.\", \"см.\", \"т.е.\", \"напр.\", \"ср.\", \"с.г.\", \"п.р.\", \"ч.п.\", \"с.г.\", \"с.р.\",\n",
        "\n",
        "    # **Turkish**\n",
        "    \"sn.\", \"dr.\", \"öğr.\", \"av.\", \"doç.\", \"prof.\", \"vs.\", \"ör.\", \"sf.\", \"ç.\", \"müh.\", \"gen.\", \"alb.\", \"uzm.\", \"şb.\",\n",
        "\n",
        "    # **Malayalam**\n",
        "    \"വി.\", \"മൂ.\", \"വി.ക.\", \"ന.ക.\", \"ഉപ.\", \"പൂ.ന.\", \"ചി.\", \"പി.\", \"ബി.\", \"ടി.\", \"ഡി.\", \"ഡി.ആർ.\", \"വി.ഡി.\",\n",
        "\n",
        "    # **Hindi**\n",
        "    \"डॉ.\", \"श्री.\", \"संपा.\", \"सं.\", \"संपा.\", \"नि.\", \"नि.सं.\", \"वि.\", \"वि.वि.\", \"सं.सं.\",\n",
        "\n",
        "    # **Tamil**\n",
        "    \"செ.\", \"நா.\", \"தி.\", \"பி.\", \"க.\", \"மு.\", \"ச.\", \"ப.\", \"ஆ.\", \"பி.எச்.டி.\",\n",
        "\n",
        "    # **Kannada**\n",
        "    \"ಶ್ರೀ.\", \"ವಿ.\", \"ಡಾ.\", \"ಪ್ರೊ.\", \"ನೋ.\", \"ಗ.ಶಿ.\", \"ಚ.ಚಿ.\", \"ಸಂಪಾ.\", \"ಸಂ.\", \"ವಿ.ವಿ.\", \"ಅ.ಪ್ರ.\",\n",
        "\n",
        "    # **Arabic**\n",
        "    \"د.\", \"م.\", \"أ.\", \"ج.\", \"س.\", \"ك.\", \"ن.\", \"ب.\", \"ش.\", \"ع.\", \"هـ.\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH2VJH9zTPQh"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower().strip()\n",
        "\n",
        "  for abbr in ABBREVIATIONS:\n",
        "      text = text.replace(abbr, abbr.replace('.', ''))\n",
        "\n",
        "  text = re.sub(r'[^\\p{L}\\s]', '', text)\n",
        "\n",
        "  return text.strip()\n",
        "\n",
        "df['Cleaned_Text'] = df['Text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPvZu3n25lQI"
      },
      "outputs": [],
      "source": [
        "def extract_trigrams(text):\n",
        "  if len(text) < 3:\n",
        "      return []\n",
        "  trigrams = [text[i:i+3] for i in range(len(text)-2)]\n",
        "  return trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3douu3pGN6vg",
        "outputId": "74687152-4571-43d6-e864-0ae3351450af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for trigram extraction: 0.7246 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "df['Trigrams'] = df['Cleaned_Text'].apply(extract_trigrams)\n",
        "\n",
        "end_time = time.time()\n",
        "trigram_time = end_time - start_time\n",
        "print(f\"Time for trigram extraction: {round(trigram_time, 4)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_3gfkrc52Yp"
      },
      "outputs": [],
      "source": [
        "D = 5000\n",
        "trigram_map = {}\n",
        "\n",
        "def generate_vector(trigram):\n",
        "  if trigram not in trigram_map:\n",
        "      trigram_map[trigram] = np.random.choice([-1, 1], D)\n",
        "  return trigram_map[trigram]\n",
        "\n",
        "def calculate_hypervector(trigrams):\n",
        "  vector = np.sum([generate_vector(t) for t in trigrams], axis=0)\n",
        "  return vector / np.linalg.norm(vector)\n",
        "\n",
        "df_filtered = df[df['Trigrams'].apply(lambda x: len(x) > 0)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr0QzeSJ6AFV",
        "outputId": "e1c520ab-8651-4c70-a21c-d1293c5c526c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for training phase: 27.2756 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "df_filtered.loc[:, 'Hypervector'] = df_filtered['Trigrams'].apply(calculate_hypervector)\n",
        "\n",
        "end_time = time.time()\n",
        "trigram_time = end_time - start_time\n",
        "print(f\"Time for training phase: {round(trigram_time, 4)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd2nBsEgJcJN"
      },
      "outputs": [],
      "source": [
        "def prepare_train_test_split(df, test_size=0.2, random_state=42):\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df['Language'])\n",
        "\n",
        "    test_invalid_rows = test_df[test_df['Cleaned_Text'].str.split().str.len() < 4]\n",
        "\n",
        "    train_df = pd.concat([train_df, test_invalid_rows])\n",
        "\n",
        "    test_df = test_df[test_df['Cleaned_Text'].str.split().str.len() >= 4]\n",
        "\n",
        "    rows_to_move = len(test_invalid_rows)\n",
        "\n",
        "    train_valid_rows = train_df[train_df['Cleaned_Text'].str.split().str.len() > 4]\n",
        "    additional_rows = train_valid_rows.sample(n=rows_to_move, random_state=random_state)\n",
        "\n",
        "    test_df = pd.concat([test_df, additional_rows])\n",
        "\n",
        "    train_df = train_df.drop(additional_rows.index)\n",
        "\n",
        "    test_df = test_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    train_df = train_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AZArFDPKBbc"
      },
      "outputs": [],
      "source": [
        "language_vectors = {}\n",
        "\n",
        "train_df, test_df = prepare_train_test_split(df_filtered)\n",
        "\n",
        "for lang in train_df['Language'].unique():\n",
        "    vectors = np.array(train_df[train_df['Language'] == lang]['Hypervector'].tolist())\n",
        "    language_vectors[lang] = np.mean(vectors, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExT36eD1Jcpf"
      },
      "outputs": [],
      "source": [
        "def predict_language(hypervector, language_vectors):\n",
        "    similarities = {lang: cosine_similarity([hypervector], [vec])[0][0] for lang, vec in language_vectors.items()}\n",
        "    return max(similarities, key=similarities.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqXKo5-MJmqP",
        "outputId": "248d7d4c-94fb-46aa-addc-8a79b7efb974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for prediction phase: 25.5676 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "test_df['Predicted_Language'] = test_df['Hypervector'].apply(lambda x: predict_language(x, language_vectors))\n",
        "\n",
        "end_time = time.time()\n",
        "trigram_time = end_time - start_time\n",
        "print(f\"Time for prediction phase: {round(trigram_time, 4)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auskF4lyMpwA",
        "outputId": "e846452a-90e6-4036-8205-f452db6c59e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 97.97%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(test_df['Language'], test_df['Predicted_Language'])\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glOrov4cdAu7",
        "outputId": "16d2bd3d-ad51-412e-a8d1-d489dc926745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrong predictions \n",
            "\n",
            "                                                  Text  Language  \\\n",
            "9                   oye cálmate juntos otra frase que.   Spanish   \n",
            "45             dina vänner jag känner mig mycket trög.  Sweedish   \n",
            "57   Des associations de ce type sont présentes en ...    French   \n",
            "367                         vi blir väldigt glada för.  Sweedish   \n",
            "378                           Jag håller 100% med dig.  Sweedish   \n",
            "\n",
            "    Predicted_Language  \n",
            "9           Portugeese  \n",
            "45              Danish  \n",
            "57               Dutch  \n",
            "367            Turkish  \n",
            "378             Danish  \n"
          ]
        }
      ],
      "source": [
        "mispredictions = test_df[test_df['Language'] != test_df['Predicted_Language']]\n",
        "\n",
        "print(f\"Wrong predictions \\n\")\n",
        "print(mispredictions[['Text', 'Language', 'Predicted_Language']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68mazHEpM8FY",
        "outputId": "56ab38de-25e2-405c-b486-46ec6479be3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Language: Russian\n"
          ]
        }
      ],
      "source": [
        "new_text = \"Это простой русский текст\"\n",
        "cleaned_text = clean_text(new_text)\n",
        "trigrams = extract_trigrams(cleaned_text)\n",
        "hypervector = calculate_hypervector(trigrams)\n",
        "predicted_language = predict_language(hypervector, language_vectors)\n",
        "\n",
        "print(f\"Predicted Language: {predicted_language}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf2tzKmIdJA-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
